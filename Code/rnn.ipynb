{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "da_2018 = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\NATPAC\\Prediction\\Data\\c_data_18.csv')\n",
    "\n",
    "da_2019 = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\NATPAC\\Prediction\\Data\\c_data_19.csv')\n",
    "\n",
    "da_2020 = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\NATPAC\\Prediction\\Data\\c_data_20.csv')\n",
    "\n",
    "da_2021 = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\NATPAC\\Prediction\\Data\\c_data_21.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_2018 = da_2018.drop_duplicates()\n",
    "da_2019 = da_2019.drop_duplicates()\n",
    "da_2020 = da_2020.drop_duplicates()\n",
    "da_2021 = da_2021.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7179, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8809, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5962, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7094, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_2021.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sail Date.</th>\n",
       "      <th>QTY.(KGS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>15876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>71366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8100</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>26000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8102</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>57600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8103</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>50096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>49160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8105</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>55800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29044 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sail Date.  QTY.(KGS)\n",
       "0     2018-01-01      13135\n",
       "1     2018-01-01      15876\n",
       "2     2018-01-01      71366\n",
       "3     2018-01-01      14000\n",
       "4     2018-01-01      24000\n",
       "...          ...        ...\n",
       "8100  2021-10-31      26000\n",
       "8102  2021-10-31      57600\n",
       "8103  2021-10-31      50096\n",
       "8104  2021-10-31      49160\n",
       "8105  2021-10-31      55800\n",
       "\n",
       "[29044 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data= pd.concat([da_2018,da_2019,da_2020,da_2021])\n",
    "merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58088"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14358"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_2018.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17618"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_2019.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11924"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_2020.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14188"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_2021.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index                                Sail Date.  QTY.(KGS)\n",
      "0          0  2018-01-012019-01-012020-01-012021-01-01      90631\n",
      "1          1  2018-01-012019-01-012020-01-012021-01-01     106436\n",
      "2          2  2018-01-012019-01-012020-01-012021-01-01     125133\n",
      "3          3  2018-01-012019-01-012020-01-012021-01-01      99153\n",
      "4          4            2018-01-012019-01-012021-01-01      87249\n",
      "...      ...                                       ...        ...\n",
      "10903  11716                                2019-12-31      35363\n",
      "10904  11717                                2019-12-31      27516\n",
      "10905  11718                                2019-12-31       2140\n",
      "10906  11720                                2019-12-31      17433\n",
      "10907  11721                                2019-12-31      14560\n",
      "\n",
      "[10908 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for multiple entries for the same date and aggregate the values\n",
    "merged_data_aggregated = merged_data.groupby(merged_data.index).sum()\n",
    "\n",
    "# Reset the index to make the date column a regular column\n",
    "merged_data_aggregated.reset_index(inplace=True)\n",
    "\n",
    "# Display the aggregated data\n",
    "print(merged_data_aggregated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.size\n",
    "\n",
    "merged_data.to_csv('combined_set.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\simple_rnn.py:130: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "726/726 [==============================] - 3s 2ms/step - loss: 0.0019\n",
      "Epoch 2/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.6685e-04\n",
      "Epoch 3/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.2587e-04\n",
      "Epoch 4/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.2624e-04\n",
      "Epoch 5/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.0891e-04\n",
      "Epoch 6/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.0734e-04\n",
      "Epoch 7/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.1011e-04\n",
      "Epoch 8/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.0431e-04\n",
      "Epoch 9/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.0181e-04\n",
      "Epoch 10/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.9524e-04\n",
      "Epoch 11/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.0172e-04\n",
      "Epoch 12/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.9360e-04\n",
      "Epoch 13/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.8614e-04\n",
      "Epoch 14/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.9066e-04\n",
      "Epoch 15/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.9304e-04\n",
      "Epoch 16/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.9213e-04\n",
      "Epoch 17/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.8443e-04\n",
      "Epoch 18/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.8296e-04\n",
      "Epoch 19/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7937e-04\n",
      "Epoch 20/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.8287e-04\n",
      "Epoch 21/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7731e-04\n",
      "Epoch 22/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.7949e-04\n",
      "Epoch 23/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.8611e-04\n",
      "Epoch 24/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7634e-04\n",
      "Epoch 25/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7768e-04\n",
      "Epoch 26/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7811e-04\n",
      "Epoch 27/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.8102e-04\n",
      "Epoch 28/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.7628e-04\n",
      "Epoch 29/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.7720e-04\n",
      "Epoch 30/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7395e-04\n",
      "Epoch 31/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7500e-04\n",
      "Epoch 32/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7360e-04\n",
      "Epoch 33/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7092e-04\n",
      "Epoch 34/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7423e-04\n",
      "Epoch 35/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7402e-04\n",
      "Epoch 36/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6859e-04\n",
      "Epoch 37/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6986e-04\n",
      "Epoch 38/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7212e-04\n",
      "Epoch 39/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.7262e-04\n",
      "Epoch 40/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6734e-04\n",
      "Epoch 41/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7624e-04\n",
      "Epoch 42/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6986e-04\n",
      "Epoch 43/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6804e-04\n",
      "Epoch 44/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6701e-04\n",
      "Epoch 45/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7128e-04\n",
      "Epoch 46/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6783e-04\n",
      "Epoch 47/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6862e-04\n",
      "Epoch 48/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6766e-04\n",
      "Epoch 49/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6991e-04\n",
      "Epoch 50/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6963e-04\n",
      "Epoch 51/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6306e-04\n",
      "Epoch 52/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6668e-04\n",
      "Epoch 53/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6845e-04\n",
      "Epoch 54/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6744e-04\n",
      "Epoch 55/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6587e-04\n",
      "Epoch 56/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6868e-04\n",
      "Epoch 57/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6546e-04\n",
      "Epoch 58/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6757e-04\n",
      "Epoch 59/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6308e-04\n",
      "Epoch 60/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6834e-04\n",
      "Epoch 61/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6659e-04\n",
      "Epoch 62/100\n",
      "726/726 [==============================] - 1s 1ms/step - loss: 3.6135e-04\n",
      "Epoch 63/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6516e-04\n",
      "Epoch 64/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.6718e-04\n",
      "Epoch 65/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.6387e-04\n",
      "Epoch 66/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6555e-04\n",
      "Epoch 67/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6386e-04\n",
      "Epoch 68/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6476e-04\n",
      "Epoch 69/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6214e-04\n",
      "Epoch 70/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6696e-04\n",
      "Epoch 71/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6223e-04\n",
      "Epoch 72/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6214e-04\n",
      "Epoch 73/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6207e-04\n",
      "Epoch 74/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6415e-04\n",
      "Epoch 75/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.6214e-04\n",
      "Epoch 76/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6341e-04\n",
      "Epoch 77/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6188e-04\n",
      "Epoch 78/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6751e-04\n",
      "Epoch 79/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6242e-04\n",
      "Epoch 80/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6121e-04\n",
      "Epoch 81/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6785e-04\n",
      "Epoch 82/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6334e-04\n",
      "Epoch 83/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6351e-04\n",
      "Epoch 84/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6459e-04\n",
      "Epoch 85/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6183e-04\n",
      "Epoch 86/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6141e-04\n",
      "Epoch 87/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6056e-04\n",
      "Epoch 88/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6064e-04\n",
      "Epoch 89/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6333e-04\n",
      "Epoch 90/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6383e-04\n",
      "Epoch 91/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6034e-04\n",
      "Epoch 92/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6244e-04\n",
      "Epoch 93/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6163e-04\n",
      "Epoch 94/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.5915e-04\n",
      "Epoch 95/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6340e-04\n",
      "Epoch 96/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6179e-04\n",
      "Epoch 97/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6055e-04\n",
      "Epoch 98/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.6157e-04\n",
      "Epoch 99/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.5899e-04\n",
      "Epoch 100/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6289e-04\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 1.6137e-04\n",
      "Mean Squared Error on test data: 0.00016137209604494274\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Read the combined dataset from the CSV file\n",
    "merged_data = pd.read_csv('combined_set.csv')\n",
    "\n",
    "# Convert 'Sail Date.' to datetime format\n",
    "merged_data['Sail Date.'] = pd.to_datetime(merged_data['Sail Date.'])\n",
    "\n",
    "# Extract year, month, and day as numerical features\n",
    "merged_data['Year'] = merged_data['Sail Date.'].dt.year\n",
    "merged_data['Month'] = merged_data['Sail Date.'].dt.month\n",
    "merged_data['Day'] = merged_data['Sail Date.'].dt.day\n",
    "\n",
    "# Drop the original 'Sail Date.' column\n",
    "merged_data.drop(columns=['Sail Date.'], inplace=True)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(merged_data)\n",
    "\n",
    "# Convert the DataFrame to a numpy array\n",
    "data_array = np.array(scaled_data)\n",
    "\n",
    "# Define the sequence length (number of time steps)\n",
    "sequence_length = 3  # Assuming you want to use past 3 months' data to predict the next month\n",
    "\n",
    "# Create sequences for input and target variables\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(data_array) - sequence_length):\n",
    "    X.append(data_array[i:i+sequence_length])\n",
    "    y.append(data_array[i+sequence_length, -1])  # Assuming the last column is the target variable\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(X))\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Define RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=50, activation='relu', input_shape=(X.shape[1], X.shape[2])),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "\n",
    "# Evaluate model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error on test data:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.0065\n",
      "Epoch 2/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.9243e-04\n",
      "Epoch 3/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.3431e-04\n",
      "Epoch 4/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.1101e-04\n",
      "Epoch 5/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 4.2423e-04\n",
      "Epoch 6/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 4.0028e-04\n",
      "Epoch 7/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 4.0156e-04\n",
      "Epoch 8/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7799e-04\n",
      "Epoch 9/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.8074e-04\n",
      "Epoch 10/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.8429e-04\n",
      "Epoch 11/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7706e-04\n",
      "Epoch 12/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6358e-04\n",
      "Epoch 13/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.7086e-04\n",
      "Epoch 14/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.6049e-04\n",
      "Epoch 15/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.5818e-04\n",
      "Epoch 16/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.5778e-04\n",
      "Epoch 17/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.5878e-04\n",
      "Epoch 18/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.5308e-04\n",
      "Epoch 19/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.5867e-04\n",
      "Epoch 20/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.4651e-04\n",
      "Epoch 21/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4583e-04\n",
      "Epoch 22/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4515e-04\n",
      "Epoch 23/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.5288e-04\n",
      "Epoch 24/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4783e-04\n",
      "Epoch 25/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.5012e-04\n",
      "Epoch 26/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3364e-04\n",
      "Epoch 27/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4436e-04\n",
      "Epoch 28/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4262e-04\n",
      "Epoch 29/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4065e-04\n",
      "Epoch 30/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4740e-04\n",
      "Epoch 31/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.4334e-04\n",
      "Epoch 32/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3880e-04\n",
      "Epoch 33/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.4044e-04\n",
      "Epoch 34/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3315e-04\n",
      "Epoch 35/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4005e-04\n",
      "Epoch 36/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3686e-04\n",
      "Epoch 37/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3508e-04\n",
      "Epoch 38/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4182e-04\n",
      "Epoch 39/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3548e-04\n",
      "Epoch 40/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4219e-04\n",
      "Epoch 41/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.4117e-04\n",
      "Epoch 42/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3976e-04\n",
      "Epoch 43/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3754e-04\n",
      "Epoch 44/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3233e-04\n",
      "Epoch 45/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3604e-04\n",
      "Epoch 46/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3259e-04\n",
      "Epoch 47/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3316e-04\n",
      "Epoch 48/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3720e-04\n",
      "Epoch 49/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3268e-04\n",
      "Epoch 50/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3299e-04\n",
      "Epoch 51/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3408e-04\n",
      "Epoch 52/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3489e-04\n",
      "Epoch 53/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3378e-04\n",
      "Epoch 54/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3329e-04\n",
      "Epoch 55/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3330e-04\n",
      "Epoch 56/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3153e-04\n",
      "Epoch 57/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3191e-04\n",
      "Epoch 58/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3053e-04\n",
      "Epoch 59/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.2974e-04\n",
      "Epoch 60/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3006e-04\n",
      "Epoch 61/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3572e-04\n",
      "Epoch 62/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3285e-04\n",
      "Epoch 63/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3089e-04\n",
      "Epoch 64/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2884e-04\n",
      "Epoch 65/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2931e-04\n",
      "Epoch 66/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2977e-04\n",
      "Epoch 67/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.2963e-04\n",
      "Epoch 68/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3149e-04\n",
      "Epoch 69/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.2998e-04\n",
      "Epoch 70/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3008e-04\n",
      "Epoch 71/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2767e-04\n",
      "Epoch 72/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3177e-04\n",
      "Epoch 73/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3521e-04\n",
      "Epoch 74/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3108e-04\n",
      "Epoch 75/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.2571e-04\n",
      "Epoch 76/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3083e-04\n",
      "Epoch 77/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2831e-04\n",
      "Epoch 78/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2841e-04\n",
      "Epoch 79/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2787e-04\n",
      "Epoch 80/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3270e-04\n",
      "Epoch 81/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2866e-04\n",
      "Epoch 82/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2776e-04\n",
      "Epoch 83/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3178e-04\n",
      "Epoch 84/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2719e-04\n",
      "Epoch 85/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2981e-04\n",
      "Epoch 86/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2605e-04\n",
      "Epoch 87/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2890e-04\n",
      "Epoch 88/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2639e-04\n",
      "Epoch 89/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2645e-04\n",
      "Epoch 90/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.2862e-04\n",
      "Epoch 91/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2386e-04\n",
      "Epoch 92/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.3053e-04\n",
      "Epoch 93/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2893e-04\n",
      "Epoch 94/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2618e-04\n",
      "Epoch 95/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2637e-04\n",
      "Epoch 96/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2705e-04\n",
      "Epoch 97/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2814e-04\n",
      "Epoch 98/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2931e-04\n",
      "Epoch 99/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2587e-04\n",
      "Epoch 100/100\n",
      "726/726 [==============================] - 1s 2ms/step - loss: 3.2981e-04\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 2.8596e-04\n",
      "Mean Squared Error on test data: 0.0002859625965356827\n",
      "182/182 [==============================] - 1s 2ms/step\n",
      "Mean Squared Error: 0.0002859626736692361\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Read the combined dataset from the CSV file\n",
    "merged_data = pd.read_csv('combined_set.csv')\n",
    "\n",
    "# Convert 'Sail Date.' to datetime format\n",
    "merged_data['Sail Date.'] = pd.to_datetime(merged_data['Sail Date.'])\n",
    "\n",
    "# Extract year, month, and day as numerical features\n",
    "merged_data['Year'] = merged_data['Sail Date.'].dt.year\n",
    "merged_data['Month'] = merged_data['Sail Date.'].dt.month\n",
    "merged_data['Day'] = merged_data['Sail Date.'].dt.day\n",
    "\n",
    "# Drop the original 'Sail Date.' column\n",
    "merged_data.drop(columns=['Sail Date.'], inplace=True)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(merged_data)\n",
    "\n",
    "# Define the sequence length (number of time steps)\n",
    "sequence_length = 3  # Assuming you want to use past 3 months' data to predict the next month\n",
    "\n",
    "# Create sequences for input and target variables\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(scaled_data) - sequence_length):\n",
    "    X.append(scaled_data[i:i+sequence_length])\n",
    "    y.append(scaled_data[i+sequence_length, -1])  # Assuming the last column is the target variable\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=50, activation='relu', input_shape=(X.shape[1], X.shape[2])),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "\n",
    "# Evaluate model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error on test data:\", mse)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "726/726 [==============================] - 4s 4ms/step - loss: 0.0024\n",
      "Epoch 2/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 4.5713e-04\n",
      "Epoch 3/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 4.1796e-04\n",
      "Epoch 4/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.9840e-04\n",
      "Epoch 5/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.9000e-04\n",
      "Epoch 6/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.9049e-04\n",
      "Epoch 7/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.9122e-04\n",
      "Epoch 8/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.7233e-04\n",
      "Epoch 9/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6370e-04\n",
      "Epoch 10/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.6381e-04\n",
      "Epoch 11/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.7056e-04\n",
      "Epoch 12/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.5844e-04\n",
      "Epoch 13/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.5001e-04\n",
      "Epoch 14/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.5722e-04\n",
      "Epoch 15/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.5432e-04\n",
      "Epoch 16/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4580e-04\n",
      "Epoch 17/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4951e-04\n",
      "Epoch 18/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4940e-04\n",
      "Epoch 19/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4460e-04\n",
      "Epoch 20/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4340e-04\n",
      "Epoch 21/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4648e-04\n",
      "Epoch 22/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4755e-04\n",
      "Epoch 23/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.4884e-04\n",
      "Epoch 24/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3943e-04\n",
      "Epoch 25/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4654e-04\n",
      "Epoch 26/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.4414e-04\n",
      "Epoch 27/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4191e-04\n",
      "Epoch 28/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3930e-04\n",
      "Epoch 29/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.4012e-04\n",
      "Epoch 30/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4487e-04\n",
      "Epoch 31/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.4248e-04\n",
      "Epoch 32/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3780e-04\n",
      "Epoch 33/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3803e-04\n",
      "Epoch 34/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.4109e-04\n",
      "Epoch 35/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3987e-04\n",
      "Epoch 36/100\n",
      "726/726 [==============================] - 3s 3ms/step - loss: 3.3830e-04\n",
      "Epoch 37/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4575e-04\n",
      "Epoch 38/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3579e-04\n",
      "Epoch 39/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.4138e-04\n",
      "Epoch 40/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3856e-04\n",
      "Epoch 41/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3642e-04\n",
      "Epoch 42/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3555e-04\n",
      "Epoch 43/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3744e-04\n",
      "Epoch 44/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3221e-04\n",
      "Epoch 45/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3744e-04\n",
      "Epoch 46/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3610e-04\n",
      "Epoch 47/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3852e-04\n",
      "Epoch 48/100\n",
      "726/726 [==============================] - 3s 3ms/step - loss: 3.3587e-04\n",
      "Epoch 49/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3884e-04\n",
      "Epoch 50/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3356e-04\n",
      "Epoch 51/100\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 3.3592e-04\n",
      "Epoch 52/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3471e-04\n",
      "Epoch 53/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3691e-04\n",
      "Epoch 54/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3546e-04\n",
      "Epoch 55/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3400e-04\n",
      "Epoch 56/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3583e-04\n",
      "Epoch 57/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3265e-04\n",
      "Epoch 58/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3282e-04\n",
      "Epoch 59/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3383e-04\n",
      "Epoch 60/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3523e-04\n",
      "Epoch 61/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3271e-04\n",
      "Epoch 62/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3401e-04\n",
      "Epoch 63/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3367e-04\n",
      "Epoch 64/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.2994e-04\n",
      "Epoch 65/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3184e-04\n",
      "Epoch 66/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3575e-04\n",
      "Epoch 67/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3613e-04\n",
      "Epoch 68/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3342e-04\n",
      "Epoch 69/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3002e-04\n",
      "Epoch 70/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3146e-04\n",
      "Epoch 71/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3197e-04\n",
      "Epoch 72/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3230e-04\n",
      "Epoch 73/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3043e-04\n",
      "Epoch 74/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.2884e-04\n",
      "Epoch 75/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3127e-04\n",
      "Epoch 76/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.2974e-04\n",
      "Epoch 77/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3217e-04\n",
      "Epoch 78/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3200e-04\n",
      "Epoch 79/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.2837e-04\n",
      "Epoch 80/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.2759e-04\n",
      "Epoch 81/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.2757e-04\n",
      "Epoch 82/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3143e-04\n",
      "Epoch 83/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3165e-04\n",
      "Epoch 84/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3009e-04\n",
      "Epoch 85/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3297e-04\n",
      "Epoch 86/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.2972e-04\n",
      "Epoch 87/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.2963e-04\n",
      "Epoch 88/100\n",
      "726/726 [==============================] - 4s 6ms/step - loss: 3.3249e-04\n",
      "Epoch 89/100\n",
      "726/726 [==============================] - 4s 6ms/step - loss: 3.3032e-04\n",
      "Epoch 90/100\n",
      "726/726 [==============================] - 4s 6ms/step - loss: 3.2981e-04\n",
      "Epoch 91/100\n",
      "726/726 [==============================] - 4s 6ms/step - loss: 3.3002e-04\n",
      "Epoch 92/100\n",
      "726/726 [==============================] - 4s 6ms/step - loss: 3.3124e-04\n",
      "Epoch 93/100\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 3.2571e-04\n",
      "Epoch 94/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3281e-04\n",
      "Epoch 95/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.2697e-04\n",
      "Epoch 96/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.2798e-04\n",
      "Epoch 97/100\n",
      "726/726 [==============================] - 2s 3ms/step - loss: 3.3180e-04\n",
      "Epoch 98/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3001e-04\n",
      "Epoch 99/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.3093e-04\n",
      "Epoch 100/100\n",
      "726/726 [==============================] - 3s 4ms/step - loss: 3.2980e-04\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 2.8769e-04\n",
      "Mean Squared Error on test data: 0.00028768987976945937\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Read the combined dataset from the CSV file\n",
    "merged_data = pd.read_csv('combined_set.csv')\n",
    "\n",
    "# Convert 'Sail Date.' to datetime format\n",
    "merged_data['Sail Date.'] = pd.to_datetime(merged_data['Sail Date.'])\n",
    "\n",
    "# Extract year, month, and day as numerical features\n",
    "merged_data['Year'] = merged_data['Sail Date.'].dt.year\n",
    "merged_data['Month'] = merged_data['Sail Date.'].dt.month\n",
    "merged_data['Day'] = merged_data['Sail Date.'].dt.day\n",
    "\n",
    "# Drop the original 'Sail Date.' column\n",
    "merged_data.drop(columns=['Sail Date.'], inplace=True)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(merged_data)\n",
    "\n",
    "# Define the sequence length (number of time steps)\n",
    "sequence_length = 3  # Assuming you want to use past 3 months' data to predict the next month\n",
    "\n",
    "# Create sequences for input and target variables\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(scaled_data) - sequence_length):\n",
    "    X.append(scaled_data[i:i+sequence_length])\n",
    "    y.append(scaled_data[i+sequence_length, -1])  # Assuming the last column is the target variable\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=50, activation='relu', input_shape=(X.shape[1], X.shape[2])),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "\n",
    "# Evaluate model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error on test data:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Predicted sales quantities for 2022:\n",
      "            Predicted Sales Quantity\n",
      "2022-01-01              82325.494251\n",
      "2022-01-02              62879.972373\n",
      "2022-01-03              85931.475355\n",
      "2022-01-04              82921.202991\n",
      "2022-01-05              62561.787840\n",
      "...                              ...\n",
      "2022-12-27              82906.033344\n",
      "2022-12-28              62564.216874\n",
      "2022-12-29              86346.102929\n",
      "2022-12-30              82906.033344\n",
      "2022-12-31              62564.216874\n",
      "\n",
      "[365 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the start and end dates for 2022\n",
    "start_date_2022 = pd.Timestamp(2022, 1, 1)\n",
    "end_date_2022 = pd.Timestamp(2022, 12, 31)\n",
    "\n",
    "# Generate a date range for 2022\n",
    "date_range_2022 = pd.date_range(start=start_date_2022, end=end_date_2022)\n",
    "\n",
    "# Initialize an empty array to store predicted sales quantities for 2022\n",
    "predicted_sales_2022 = []\n",
    "\n",
    "# Initialize the last sequence with the last known data from the test set\n",
    "last_sequence = X_test[-1:]\n",
    "\n",
    "# Iterate over each date in 2022\n",
    "for i, date in enumerate(date_range_2022):\n",
    "    # Predict the sales quantity for the next date\n",
    "    predicted_sales_scaled = model.predict(last_sequence)\n",
    "    \n",
    "    # Perform inverse transformation to get the predicted sales quantity in original scale\n",
    "    predicted_sales = scaler.inverse_transform(np.array([[predicted_sales_scaled[0][0], 0, 0, 0]]))\n",
    "    \n",
    "    # Store the predicted sales quantity for the current date\n",
    "    predicted_sales_2022.append(predicted_sales[0][0])\n",
    "    \n",
    "    # Update the last sequence with the predicted sales quantity for the next date\n",
    "    last_sequence = np.roll(last_sequence, -1, axis=1)  # Shift elements to the left by one\n",
    "    last_sequence[0, -1, 0] = predicted_sales_scaled[0][0]  # Update the last element of the last sequence\n",
    "\n",
    "# Create a DataFrame to store the predicted sales quantities with dates as index\n",
    "predicted_sales_df = pd.DataFrame(predicted_sales_2022, index=date_range_2022, columns=['Predicted Sales Quantity'])\n",
    "\n",
    "print(\"Predicted sales quantities for 2022:\")\n",
    "print(predicted_sales_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
